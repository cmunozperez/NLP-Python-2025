{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4kv19CLTC7ZZfeYGw+c1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmunozperez/NLP-Python-2025/blob/main/Notebook_3_Naive_Bayes_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicciones con Naive Bayes\n",
        "\n",
        "Empezamos realizando algunas importaciones.\n",
        "\n",
        "- Regex (o expresiones regulares) es una herramienta para buscar, extraer o reemplazar texto usando patrones. Se usa con el módulo re en Python.\n",
        "- spaCy es una biblioteca de procesamiento de lenguaje natural (NLP) en Python. Permite analizar textos: separar palabras, identificar entidades (como nombres de personas, lugares), etc."
      ],
      "metadata": {
        "id": "AlgzuB43NHbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOWnatqryqLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c941e155-d580-41f0-9eb5-339cd676b481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import re # regex\n",
        "import spacy # Para preprocesar los datos\n",
        "\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a utilizar el modelo \"grande\" de spaCy para el inglés. Es bastante más lento que los modelos pequeños, pero no es algo que vaya a afectarnos demasiado para el preprocesamiento."
      ],
      "metadata": {
        "id": "RZIHKaTZPbUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "ej1 = nlp(\"This study deals with syntactic structure both in the broad sense (as opposed to semantics) and the narrow sense (as opposed to phonemics and morphology).\")\n",
        "\n",
        "for token in ej1:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "id": "vpYdidMkysWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5db16b3-8524-4e41-f02c-af374ed36633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This\n",
            "study\n",
            "deals\n",
            "with\n",
            "syntactic\n",
            "structure\n",
            "both\n",
            "in\n",
            "the\n",
            "broad\n",
            "sense\n",
            "(\n",
            "as\n",
            "opposed\n",
            "to\n",
            "semantics\n",
            ")\n",
            "and\n",
            "the\n",
            "narrow\n",
            "sense\n",
            "(\n",
            "as\n",
            "opposed\n",
            "to\n",
            "phonemics\n",
            "and\n",
            "morphology\n",
            ")\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vimos ayer, podemos obtener automáticamente la categoría de las palabras."
      ],
      "metadata": {
        "id": "rwYW6gjYP3Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in ej1:\n",
        "    print(f\"{token.text} -> {token.pos_}\")"
      ],
      "metadata": {
        "id": "m4zpljxF2GoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbaafbf2-ec71-43bd-9d96-940a342b8040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This -> DET\n",
            "study -> NOUN\n",
            "deals -> VERB\n",
            "with -> ADP\n",
            "syntactic -> ADJ\n",
            "structure -> NOUN\n",
            "both -> PRON\n",
            "in -> ADP\n",
            "the -> DET\n",
            "broad -> ADJ\n",
            "sense -> NOUN\n",
            "( -> PUNCT\n",
            "as -> SCONJ\n",
            "opposed -> VERB\n",
            "to -> ADP\n",
            "semantics -> NOUN\n",
            ") -> PUNCT\n",
            "and -> CCONJ\n",
            "the -> DET\n",
            "narrow -> ADJ\n",
            "sense -> NOUN\n",
            "( -> PUNCT\n",
            "as -> SCONJ\n",
            "opposed -> VERB\n",
            "to -> ADP\n",
            "phonemics -> NOUN\n",
            "and -> CCONJ\n",
            "morphology -> NOUN\n",
            ") -> PUNCT\n",
            ". -> PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos hacer *Named Entity Recognition* (NER), i.e., una técnica de procesamiento de lenguaje natural que identifica y clasifica entidades en un texto de acuerdo a una tipología.\n",
        "\n",
        "- PERSON: gente real o no\n",
        "- NORP: nacionalidades o grupos políticos, religiosos, etc.\n",
        "- FAC: edificioes, aeropuertos, calles, etc.\n",
        "- ORG: Empresas, instituciones\n",
        "- GPE: ciudades, provincias, países\n",
        "- Otras..."
      ],
      "metadata": {
        "id": "7U0LPMUY8lEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ej2 = nlp(\"Lucio Fulci, an Italian film director known for his work in horror cinema, was born in Rome in 1927 and directed cult classics like The Beyond and Zombie Flesh Eaters.\")\n",
        "\n",
        "for ent in ej2.ents:\n",
        "    print(f\"{ent.text} -> {ent.label_}\")"
      ],
      "metadata": {
        "id": "eTB_27UT2ehu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e10fcb9-b949-4115-c948-da3f4c7b8ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lucio Fulci -> PERSON\n",
            "Italian -> NORP\n",
            "Rome -> GPE\n",
            "1927 -> DATE\n",
            "The Beyond and Zombie Flesh Eaters -> WORK_OF_ART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta celda contiene la funcionalidad que vamos a utilizar: la lematización. Sirve para obtener ``la forma de diccionario'' de una palabra, para facilitar establecer similitudes entre los textos."
      ],
      "metadata": {
        "id": "muaxTWTdQb9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ej3 = nlp(\"The children ran to the geese, who had eaten the thieves' loaves, while the mice hid from the teeth of the wolves.\")\n",
        "\n",
        "for token in ej3:\n",
        "    print(f\"{token.text} -> {token.lemma_}\")"
      ],
      "metadata": {
        "id": "4Y_E6V0d278L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366ddd7a-4fe4-4b95-b9c0-2e78bbaf9c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The -> the\n",
            "children -> child\n",
            "ran -> run\n",
            "to -> to\n",
            "the -> the\n",
            "geese -> goose\n",
            ", -> ,\n",
            "who -> who\n",
            "had -> have\n",
            "eaten -> eat\n",
            "the -> the\n",
            "thieves -> thief\n",
            "' -> '\n",
            "loaves -> loaf\n",
            ", -> ,\n",
            "while -> while\n",
            "the -> the\n",
            "mice -> mouse\n",
            "hid -> hide\n",
            "from -> from\n",
            "the -> the\n",
            "teeth -> tooth\n",
            "of -> of\n",
            "the -> the\n",
            "wolves -> wolf\n",
            ". -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para lematizar, vamos a usar la siguiente función."
      ],
      "metadata": {
        "id": "xuJKYzEzRmzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])"
      ],
      "metadata": {
        "id": "3NYeOPnM0hb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejemplo = lemmatize('This is an English sentence that needs to be analyzed.')\n",
        "ejemplo"
      ],
      "metadata": {
        "id": "8hCcmW1e1x2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f91152e8-fe43-48ef-9ced-40f2fe834db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this be an english sentence that need to be analyze'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generando el DataFrame para training\n",
        "\n",
        "Antes de entrenar un modelo de Naive Bayes, es necesario transformar el DataFrame porque el modelo no puede trabajar directamente con texto crudo o datos categóricos. Además de lematizar, los textos deben convertirse en vectores numéricos (por ejemplo, usando CountVectorizer) que representen la frecuencia o importancia de las palabras."
      ],
      "metadata": {
        "id": "lGHiSgBj-sCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto abre el archivo CSV.\n",
        "\n"
      ],
      "metadata": {
        "id": "X-WNTVbw3i0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv = \"https://raw.githubusercontent.com/cmunozperez/lingbuzz_data_analysis/refs/heads/main/lingbuzz_002_007537.csv\"\n"
      ],
      "metadata": {
        "id": "0tkWoDpL2Tap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo llevamos a un DataFrame"
      ],
      "metadata": {
        "id": "i7aFewYvSkPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(csv)"
      ],
      "metadata": {
        "id": "LfpuVHqK_GoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiamos NaNs."
      ],
      "metadata": {
        "id": "rlynMCJTSnGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Title'], inplace=True)\n",
        "\n",
        "df['Abstract'] = df['Abstract'].fillna('')\n",
        "df['Keywords'] = df['Keywords'].fillna('')"
      ],
      "metadata": {
        "id": "CmFYn_1K_LTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiamos el formato de las fechas."
      ],
      "metadata": {
        "id": "O63VAh_-SrUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], format='%B %Y')\n",
        "df['Date'] = df['Date'].dt.to_period('M')"
      ],
      "metadata": {
        "id": "jXMOO4N2Bogb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*One-hot encoding* es una técnica para convertir variables categóricas (e.g., la disciplina a la que pertenece un manuscrito) en una representación numérica binaria. Cada categoría se transforma en una nueva columna que toma el valor 1 si el registro pertenece a esa categoría, o 0 si no."
      ],
      "metadata": {
        "id": "7GBMCdLOS-Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disciplines = ['phonology', 'morphology', 'syntax', 'semantics']\n",
        "\n",
        "for word in disciplines:\n",
        "  df[word] = df['Keywords'].apply(lambda x: 1 if word in x else 0)"
      ],
      "metadata": {
        "id": "ewmszeyP_LQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combinamos el abstract con su título en una única celda a la que llamaremos \"Text\". Esta es la variable *x* que utilizaremos para predecir la etiqueta *y* (la disciplina)."
      ],
      "metadata": {
        "id": "Ad6KqS9zTh07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Title'] + '. ' + df['Abstract']"
      ],
      "metadata": {
        "id": "wJoMRTJc_LOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta: ¿qué pasa si nuestra muestra tiene muchas más muestras de una clase que de otras? Por ejemplo, si entrenamos un clasificador que reconozca spam, y lo entrenamos con 100.000 mensajes normales y solo 1000 mensajes de spam, ¿qué pasaría?"
      ],
      "metadata": {
        "id": "sdtAzzE6AFQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_count = {dis: df[dis].sum() for dis in disciplines}\n",
        "label_count"
      ],
      "metadata": {
        "id": "K-bTJRtG_LLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e14418-663b-4811-f915-2f37263ff6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'phonology': np.int64(1359),\n",
              " 'morphology': np.int64(1995),\n",
              " 'syntax': np.int64(5215),\n",
              " 'semantics': np.int64(2769)}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establecemos una variable con el número *n* de entradas para la disciplina menos representada en el repositorio."
      ],
      "metadata": {
        "id": "q3KDBwfUUko4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowest_label_count = min(label_count.values())"
      ],
      "metadata": {
        "id": "PAFgtBuo_LJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y tomamos las *n* entradas más recientes de cada disciplina."
      ],
      "metadata": {
        "id": "sURu6nYlUrbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_abstracts = []\n",
        "\n",
        "for dis in disciplines:\n",
        "    small_df = df[df[dis] == 1]\n",
        "    small_df = small_df.sort_values(by='Date', ascending=False)\n",
        "    small_df = small_df.head(lowest_label_count)\n",
        "    selected_abstracts.append(small_df)"
      ],
      "metadata": {
        "id": "TNFSXgfG_LGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combinamos nuevamente en un DataFrame df. Aprovechemos también para deshacernos de la información que no vamos a utilizar en el entrenamiento (lugar de publicación, id, cantidad de descargas, etc.)."
      ],
      "metadata": {
        "id": "EOJMvkveU45X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(selected_abstracts, ignore_index=False, join='inner')\n",
        "\n",
        "df = df[['Text', 'phonology', 'morphology', 'syntax', 'semantics']]\n",
        "df"
      ],
      "metadata": {
        "id": "Xrjibw-4_LEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "fb65251e-4636-49e6-ef7c-719a657b9641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text  phonology  \\\n",
              "7295  Les langues des signes : en France et à trave...          1   \n",
              "6941  Review of: [Polinsky et al] Oxford Handbook of...          1   \n",
              "7138  Prosodic strength in Campidanese Sardinian as ...          1   \n",
              "6991  A Neo-Trubetzkoyan approach to phonotactic lea...          1   \n",
              "7346  What phonology is and why it should be. This c...          1   \n",
              "...                                                 ...        ...   \n",
              "3512  Genericity in event semantics: A look at Yorub...          0   \n",
              "4082  Modes of presentation in attitude reports. In ...          0   \n",
              "3686  Justifications for a discontinuity theory of l...          0   \n",
              "4162  Reducing coreference to co-binding. The paper ...          0   \n",
              "3624  From negative cleft to external negator: Easte...          0   \n",
              "\n",
              "      morphology  syntax  semantics  \n",
              "7295           0       1          1  \n",
              "6941           1       1          1  \n",
              "7138           0       0          0  \n",
              "6991           0       0          0  \n",
              "7346           0       0          0  \n",
              "...          ...     ...        ...  \n",
              "3512           0       0          1  \n",
              "4082           0       0          1  \n",
              "3686           0       1          1  \n",
              "4162           0       1          1  \n",
              "3624           0       1          1  \n",
              "\n",
              "[5436 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0079455c-77fb-48b4-b22c-dc9b4fde56fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>phonology</th>\n",
              "      <th>morphology</th>\n",
              "      <th>syntax</th>\n",
              "      <th>semantics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7295</th>\n",
              "      <td>Les langues des signes : en France et à trave...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6941</th>\n",
              "      <td>Review of: [Polinsky et al] Oxford Handbook of...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7138</th>\n",
              "      <td>Prosodic strength in Campidanese Sardinian as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6991</th>\n",
              "      <td>A Neo-Trubetzkoyan approach to phonotactic lea...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7346</th>\n",
              "      <td>What phonology is and why it should be. This c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3512</th>\n",
              "      <td>Genericity in event semantics: A look at Yorub...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4082</th>\n",
              "      <td>Modes of presentation in attitude reports. In ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3686</th>\n",
              "      <td>Justifications for a discontinuity theory of l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4162</th>\n",
              "      <td>Reducing coreference to co-binding. The paper ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3624</th>\n",
              "      <td>From negative cleft to external negator: Easte...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5436 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0079455c-77fb-48b4-b22c-dc9b4fde56fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0079455c-77fb-48b4-b22c-dc9b4fde56fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0079455c-77fb-48b4-b22c-dc9b4fde56fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47f87ffb-49ea-4849-b3c2-a9811b048e49\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47f87ffb-49ea-4849-b3c2-a9811b048e49')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47f87ffb-49ea-4849-b3c2-a9811b048e49 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ad2776ba-1276-463f-9383-7602a2ac5aad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ad2776ba-1276-463f-9383-7602a2ac5aad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5436,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3935,\n        \"samples\": [\n          \"Failed gender agreement in L1 English L2 Spanish: Syntactic or lexical problem?. A recent proposal attributes morphosyntactic issues in L2 to lexical factors (Gr\\u00fcter et al. 2012; Hopp 2013). According to this lexical account, issues with gender agreement are caused by gender assignment issues \\u2013 a failure to assign a word to a target-like class. We elaborate on this idea by exploring three potential cues to gender assignment: 1) semantic gender relating to sex (e.g. \\u2018girl\\u2019 vs. \\u2018boy\\u2019) 2) morphophonological cues, and 3) morphosyntactic agreement cues. Semantic and morphophonological cues may facilitate gender agreement only for a subset of nouns, whereas agreement cues can do so for all nouns, including opaque gender nouns that do not have semantic gender.\\r\\n\\r\\nSeventeen low proficiency and sixteen high proficiency L1 English L2 Spanish speakers and eighteen native Spanish controls judged the grammaticality of 60 experimental sentences. We compared participants\\u2019 gender agreement accuracy and reaction times (RTs) on experimental items with and without semantic gender, and with and without transparent gender morphemes. Semantic gender did not serve as a cue for gender assignment/agreement; instead, it slowed down RTs in high proficiency and control participants. Morphophonological cues significantly increased accuracy and decreased RTs in all groups. Finally, agreement cues did not seem to help low proficiency learners, since their accuracy on opaque nouns was barely above chance. By contrast, high proficiency learners exhibited native-like accuracy on opaque nouns. These findings support the lexical accounts of L2 gender agreement difficulties, adding more data to the growing body of research in this field.\",\n          \"Phonology. This is a very rough draft of a textbook on phonological theory. I am posting it here to get feedback, but also because I am using it in an online video course I am taping (in Dutch) for students and everybody else who might be interested. \",\n          \"Limited-control predicates in western Austronesia: stative, dynamic, or none of the above?. In many western Austronesian languages, the fact that an agentive argument lacks full control is morphologically marked on the verb. The formatives used for this purpose are often also found on stative predicates, and it has been suggested that limited-control predicates are stative-like in that they denote the result state of a given eventuality. Here we argue that limited-control predicates differ from both stative and dynamic predicates, and constitute a category of their own. Limited-control marking primarily pertains to agentivity and not to aspectual structure, and, importantly, is only used when control is at issue. With respect to the frequent overlaps with stative morphology, we argue that historically speaking, limited-control and stative marking have a common origin. While the current investigation does not include a full account of the historical developments leading to two synchronically separate categories (stative and limited-control), we provide evidence for the hypothesis that perception predicates had a major role to play in this development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phonology\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"morphology\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"syntax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semantics\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y finalmente aplicamos la lematización sobre la columna \"Text\". Esto tarda cuatro minutos veintisiete segundos."
      ],
      "metadata": {
        "id": "_v0p68eRVgKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Text'].apply(lemmatize)"
      ],
      "metadata": {
        "id": "s0krOw6H_LBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "HnHvnb0GFalN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando el modelo"
      ],
      "metadata": {
        "id": "eXx_X9zbGHET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empecemos con las importaciones necesarias para el entrenamiento.\n",
        "\n",
        "- train_test_split: divide los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "- CountVectorizer: convierte texto en una matriz de conteo de palabras (bolsa de palabras).\n",
        "\n",
        "- OneVsRestClassifier: es un wrap que permite entrenar un clasificador con etiquetas múltiples.\n",
        "\n",
        "- MultinomialNB: clasificador Naive Bayes.\n",
        "\n",
        "- classification_report: muestra métricas como precision, recall y F1 para evaluar el modelo."
      ],
      "metadata": {
        "id": "KxEWYnYibGBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "ff7lWXcC0UJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El texto de cada artículo constituye los \"datos de entrada\". Lo que queremos es que nos prediga la disciplina."
      ],
      "metadata": {
        "id": "BBXxls7HbniE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['Text']\n",
        "y = df[['phonology', 'morphology', 'syntax', 'semantics']]"
      ],
      "metadata": {
        "id": "QFQ7Xlv-_K6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicamos el vectorizador. Dejamos de lado las *stopwords* típicas del inglés. Además, ignoramos palabras que aparezcan en el 75% de los textos (y que, por tanto, no permitan distinguirlos)."
      ],
      "metadata": {
        "id": "IM6sXUe8MKOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english', max_df=0.75)\n",
        "X_vec = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "vzJ6OUOD_K3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos los datos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "MUFr7b8CcPbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gN6RR20f_Kz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y entrenamos nuestro clasificador."
      ],
      "metadata": {
        "id": "K_lX3MDScUUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = OneVsRestClassifier(MultinomialNB())\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KAdqRubj_Ksu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "fa59395c-4d80-4833-8cc7-c55c519a78f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=MultinomialNB())"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=MultinomialNB())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=MultinomialNB())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: MultinomialNB</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probando el modelo"
      ],
      "metadata": {
        "id": "VJDP-Bk3IsBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=y.columns))"
      ],
      "metadata": {
        "id": "cNZl8DTEHB3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b8d078-61fe-492a-e8cd-0781088476bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   phonology       0.88      0.91      0.90       419\n",
            "  morphology       0.82      0.90      0.86       515\n",
            "      syntax       0.91      0.93      0.92       721\n",
            "   semantics       0.85      0.88      0.87       498\n",
            "\n",
            "   micro avg       0.87      0.91      0.89      2153\n",
            "   macro avg       0.87      0.90      0.89      2153\n",
            "weighted avg       0.87      0.91      0.89      2153\n",
            " samples avg       0.89      0.92      0.88      2153\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bueno, eso es todo: nuestro modelo está terminado. Lo único que necesitamos es una manera de usarlo con abstracts nuevos que queramos categorizar. Podemos escribir una función para esto."
      ],
      "metadata": {
        "id": "B2F6IGHacdpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text_input(clf, vectorizer):\n",
        "\n",
        "    text = input(\"Dame un abstract de lingüística en inglés:\\n\").strip()\n",
        "    if not text:\n",
        "        print(\"No me diste un abstract\")\n",
        "\n",
        "\n",
        "    doc = nlp(text)\n",
        "    lemmatized_text = ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
        "\n",
        "    X_vec = vectorizer.transform([lemmatized_text])\n",
        "\n",
        "    prediction = clf.predict(X_vec)[0]\n",
        "\n",
        "    labels = ['phonology', 'morphology', 'syntax', 'semantics']\n",
        "    #print(zip(labels,prediction))\n",
        "\n",
        "    predicted_labels = [label for label, val in zip(labels, prediction) if val == 1]\n",
        "\n",
        "    if predicted_labels:\n",
        "        print(\"Disciplina:\", \", \".join(predicted_labels))\n",
        "    else:\n",
        "        print(\"Ninguna.\")\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "KT4y5CRRI_M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acá probamos la función con el clasificador y el vectorizador que ya instanciamos."
      ],
      "metadata": {
        "id": "vysyOJw4ddR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classify_text_input(clf, vectorizer)"
      ],
      "metadata": {
        "id": "PY5cOTffJ7d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd71479-ae1b-4a64-e77f-cffebc18e0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dame un abstract de lingüística en inglés:\n",
            "pedro fue al teatro ayer\n",
            "Disciplina: morphology, syntax, semantics\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['morphology', 'syntax', 'semantics']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LingPeer\n",
        "\n",
        "En su base, LingPeer no difiere demasiado de lo que acabamos de hacer. La distinción relevante a nuestros fines es que\n",
        "\n",
        "- en vez de utilizar el abstract para predecir a qué disciplina pertenece,\n",
        "- lo usa para intentar predecir quién es su autor.\n",
        "\n",
        "No vamos a hacer todos los pasos de preprocesamiento nuevamente. Solo hay uno que creo es importante destacar: el reemplazo de keywords de más de una palabra por un placeholder (ver slide correspondiente) ."
      ],
      "metadata": {
        "id": "MeMXrQ6aoIK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Download the file using wget\n",
        "!wget -O n_grams.pkl https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/n_grams.pkl\n",
        "\n",
        "# Load the file\n",
        "n_grams = joblib.load(\"n_grams.pkl\")"
      ],
      "metadata": {
        "id": "6n4mDqlMgHQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3722cf2e-5ee8-498b-c09a-c9c522c5897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 22:49:04--  https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/n_grams.pkl\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/n_grams.pkl [following]\n",
            "--2025-07-30 22:49:04--  https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/n_grams.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 189231 (185K) [application/octet-stream]\n",
            "Saving to: ‘n_grams.pkl’\n",
            "\n",
            "n_grams.pkl         100%[===================>] 184.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-07-30 22:49:04 (5.46 MB/s) - ‘n_grams.pkl’ saved [189231/189231]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams"
      ],
      "metadata": {
        "collapsed": true,
        "id": "syTQ_AtHuSBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c12492-b2a2-40ae-d3ab-7081d3e3ace2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'head marking': 'ngram0',\n",
              " 'dependent mark': 'ngram1',\n",
              " 'extended projection': 'ngram2',\n",
              " 'double access reading': 'ngram3',\n",
              " 'sequence of tense': 'ngram4',\n",
              " 'tense agreement': 'ngram5',\n",
              " 'tense computation': 'ngram6',\n",
              " 'the syntax pf correlation': 'ngram7',\n",
              " 'mandarin chinese': 'ngram8',\n",
              " 'gradable predicate': 'ngram9',\n",
              " 'degree abstraction': 'ngram10',\n",
              " 'degree comparison': 'ngram11',\n",
              " 'that less clause': 'ngram12',\n",
              " 'dynamic phase': 'ngram13',\n",
              " 'prosodic morphology': 'ngram14',\n",
              " 'optimality theory': 'ngram15',\n",
              " 'wh movement': 'ngram16',\n",
              " 'wh morphology': 'ngram17',\n",
              " 'complementizer agreement': 'ngram18',\n",
              " 'subject non subject asymmetry': 'ngram19',\n",
              " 'feature co occurrence': 'ngram20',\n",
              " 'complementizer allomorphy': 'ngram21',\n",
              " 'nominal parameter': 'ngram22',\n",
              " 'pro drop': 'ngram23',\n",
              " 'partial null subject language': 'ngram24',\n",
              " 'rich agreement null subject language': 'ngram25',\n",
              " 'discourse pro drop language': 'ngram26',\n",
              " 'semi pro drop language': 'ngram27',\n",
              " 'null np anaphora': 'ngram28',\n",
              " 'type shift': 'ngram29',\n",
              " 'montague grammar': 'ngram30',\n",
              " 'universal grammar': 'ngram31',\n",
              " 'course note': 'ngram32',\n",
              " 'operator movement': 'ngram33',\n",
              " 'relative clause': 'ngram34',\n",
              " 'improper movement': 'ngram35',\n",
              " 'tough movement': 'ngram36',\n",
              " 'match analysis': 'ngram37',\n",
              " 'principle c': 'ngram38',\n",
              " 'that trace effect': 'ngram39',\n",
              " 'anti locality': 'ngram40',\n",
              " 'cyclic linearization': 'ngram41',\n",
              " 'sign language': 'ngram42',\n",
              " 'context shift': 'ngram43',\n",
              " 'role shift': 'ngram44',\n",
              " 'knowledge representation': 'ngram45',\n",
              " 'argument from acquisition': 'ngram46',\n",
              " 'realistic input': 'ngram47',\n",
              " 'algebraic semantic': 'ngram48',\n",
              " 'for adverbial': 'ngram49',\n",
              " 'distance distributivity': 'ngram50',\n",
              " 'crosslinguistic semantic': 'ngram51',\n",
              " 'adnominal each': 'ngram52',\n",
              " 'adverbial each': 'ngram53',\n",
              " 'quantifier float': 'ngram54',\n",
              " 'mass term': 'ngram55',\n",
              " 'leave periphery': 'ngram56',\n",
              " 'property concept': 'ngram57',\n",
              " 'mass noun': 'ngram58',\n",
              " 'x stranding xp ellipsis': 'ngram59',\n",
              " 'verb phrase ellipsis': 'ngram60',\n",
              " 'verb stranding': 'ngram61',\n",
              " 'verb movement': 'ngram62',\n",
              " 'verb second': 'ngram63',\n",
              " 'I word': 'ngram64',\n",
              " 'nominal ellipsis': 'ngram65',\n",
              " 'empty noun': 'ngram66',\n",
              " 'null argument': 'ngram67',\n",
              " 'locative noun class': 'ngram68',\n",
              " 'locative noun': 'ngram69',\n",
              " 'evaluation metric': 'ngram70',\n",
              " 'minimum description length': 'ngram71',\n",
              " 'morpheme structure constraint': 'ngram72',\n",
              " 'richness of the base': 'ngram73',\n",
              " 'se ra': 'ngram74',\n",
              " 'imperfect subjunctive': 'ngram75',\n",
              " 'ergative agreement': 'ngram76',\n",
              " 'templatic morphology': 'ngram77',\n",
              " 'non finite clause': 'ngram78',\n",
              " 'interval theory': 'ngram79',\n",
              " 'little v': 'ngram80',\n",
              " 'kratzerian voice': 'ngram81',\n",
              " 'functional sequence fseq': 'ngram82',\n",
              " 'that trace': 'ngram83',\n",
              " 'complementizer trace': 'ngram84',\n",
              " 'fix subject': 'ngram85',\n",
              " 'empty category principle': 'ngram86',\n",
              " 'nominative island condition': 'ngram87',\n",
              " 'paradigm gap': 'ngram88',\n",
              " 'primate linguistic': 'ngram89',\n",
              " 'alarm call': 'ngram90',\n",
              " 'formal semantic': 'ngram91',\n",
              " 'formal pragmatic': 'ngram92',\n",
              " 'titi monkeys': 'ngram93',\n",
              " 'focus intervention': 'ngram94',\n",
              " 'alternative semantic': 'ngram95',\n",
              " 'adjectival inflection': 'ngram96',\n",
              " 'ein word': 'ngram97',\n",
              " 'sentence final particle': 'ngram98',\n",
              " 'final over final constraint': 'ngram99',\n",
              " 'fofc domain': 'ngram100',\n",
              " 'spell out': 'ngram101',\n",
              " 'vp ellipsis': 'ngram102',\n",
              " 'syntactic   identity': 'ngram103',\n",
              " 'hybrid type logical categorial grammar': 'ngram104',\n",
              " 'contextual restriction': 'ngram105',\n",
              " 'agreement by correspondence': 'ngram106',\n",
              " 'q theory': 'ngram107',\n",
              " 'autosegmental phonology': 'ngram108',\n",
              " 'correspondence theory': 'ngram109',\n",
              " 'glue semantic': 'ngram110',\n",
              " 'complex predicate': 'ngram111',\n",
              " 'distributive attribute': 'ngram112',\n",
              " 'modify numeral': 'ngram113',\n",
              " 'dative alternation': 'ngram114',\n",
              " 'historical change': 'ngram115',\n",
              " 'optional agreement': 'ngram116',\n",
              " 'spatial preposition': 'ngram117',\n",
              " 'non restrictive relative clause': 'ngram118',\n",
              " 'multiple wh question': 'ngram119',\n",
              " 'wh in situ': 'ngram120',\n",
              " 'intervention effect': 'ngram121',\n",
              " 'covert movement': 'ngram122',\n",
              " 'top down and bottom up derivation': 'ngram123',\n",
              " 'scalar implicature': 'ngram124',\n",
              " 'conventional implicature': 'ngram125',\n",
              " 'partial control': 'ngram126',\n",
              " 'comitative phrase': 'ngram127',\n",
              " 'semantic plurality': 'ngram128',\n",
              " 'auxiliary selection': 'ngram129',\n",
              " 'oblique subject': 'ngram130',\n",
              " 'empirical evidence': 'ngram131',\n",
              " 'minimal pair': 'ngram132',\n",
              " 'scope economy': 'ngram133',\n",
              " 'clause boundedness': 'ngram134',\n",
              " 'belief verb': 'ngram135',\n",
              " 'negative bias': 'ngram136',\n",
              " 'attitude verb': 'ngram137',\n",
              " 'lexical semantic': 'ngram138',\n",
              " 'learn bias': 'ngram139',\n",
              " 'second position': 'ngram140',\n",
              " 'verb cluster': 'ngram141',\n",
              " 'word order': 'ngram142',\n",
              " 'linear asymmetry': 'ngram143',\n",
              " 'universal 20': 'ngram144',\n",
              " 'modal verb': 'ngram145',\n",
              " 'separable prefix': 'ngram146',\n",
              " 'verbal particle': 'ngram147',\n",
              " 'long distance reflexive': 'ngram148',\n",
              " 'work memory': 'ngram149',\n",
              " 'sentence processing': 'ngram150',\n",
              " 'quantifier domain restriction': 'ngram151',\n",
              " 'inverse scope': 'ngram152',\n",
              " 'clitic movement': 'ngram153',\n",
              " 'deficient pronoun': 'ngram154',\n",
              " 'minimal pronoun': 'ngram155',\n",
              " 'person case constraint': 'ngram156',\n",
              " 'unvalued interpretable feature': 'ngram157',\n",
              " 'expletive insertion': 'ngram158',\n",
              " 'extend projection principle': 'ngram159',\n",
              " 'google search': 'ngram160',\n",
              " 'impersonal clause': 'ngram161',\n",
              " 'stylistic fronting': 'ngram162',\n",
              " 'verb initial adverbial clause': 'ngram163',\n",
              " 'word order frequency': 'ngram164',\n",
              " 'property concept sentence': 'ngram165',\n",
              " 'crosslinguistic variation': 'ngram166',\n",
              " 'semantic variation': 'ngram167',\n",
              " 'co speech gesture': 'ngram168',\n",
              " 'projection problem for co speech gesture': 'ngram169',\n",
              " 'artificial language': 'ngram170',\n",
              " 'm principle': 'ngram171',\n",
              " 'exempt anaphor': 'ngram172',\n",
              " 'condition a of bind theory': 'ngram173',\n",
              " 'perspective center': 'ngram174',\n",
              " 'logophoric operator': 'ngram175',\n",
              " 'close conjunct agreement': 'ngram176',\n",
              " 'serbo croatian': 'ngram177',\n",
              " 'de re': 'ngram178',\n",
              " 'de dicto': 'ngram179',\n",
              " 'attitude report': 'ngram180',\n",
              " \"frege 's puzzle\": 'ngram181',\n",
              " 'word learn': 'ngram182',\n",
              " 'experimental syntax': 'ngram183',\n",
              " 'experimental semantic': 'ngram184',\n",
              " 'computational modeling': 'ngram185',\n",
              " 'subcategorization frame': 'ngram186',\n",
              " 'clausal embed': 'ngram187',\n",
              " 'argument structure': 'ngram188',\n",
              " 'head movement': 'ngram189',\n",
              " 'verb raise': 'ngram190',\n",
              " 'japanese syntax': 'ngram191',\n",
              " 'distribute morphology': 'ngram192',\n",
              " 'thematic raising': 'ngram193',\n",
              " 'dp structure': 'ngram194',\n",
              " 'complex proper name': 'ngram195',\n",
              " 'lexically freeze': 'ngram196',\n",
              " 'opaque and transparent morpho syntax': 'ngram197',\n",
              " 'presupposition projection': 'ngram198',\n",
              " 'be articulate': 'ngram199',\n",
              " 'transparency theory': 'ngram200',\n",
              " 'incremental presupposition projection': 'ngram201',\n",
              " 'null subject': 'ngram202',\n",
              " 'old english': 'ngram203',\n",
              " 'lindisfarne gospel': 'ngram204',\n",
              " 'verb double': 'ngram205',\n",
              " 'rule order': 'ngram206',\n",
              " 'asante twi': 'ngram207',\n",
              " \"a'-head movement\": 'ngram208',\n",
              " 'chain reduction': 'ngram209',\n",
              " 'head movement into specifier': 'ngram210',\n",
              " 'feature geometry': 'ngram211',\n",
              " 'relativise probe': 'ngram212',\n",
              " 'order of operation': 'ngram213',\n",
              " 'monkey semantic': 'ngram214',\n",
              " 'monkey linguistic': 'ngram215',\n",
              " 'ineffability bias vehicle change': 'ngram216',\n",
              " 'identity condition': 'ngram217',\n",
              " 'sign language semantic': 'ngram218',\n",
              " 'post speech gesture': 'ngram219',\n",
              " 'mental lexicon': 'ngram220',\n",
              " 'single terminal insertion': 'ngram221',\n",
              " 'stem storage': 'ngram222',\n",
              " 'zero morph': 'ngram223',\n",
              " 'phonologically drive allomorph selection': 'ngram224',\n",
              " 'stratal optimality theory': 'ngram225',\n",
              " 'word and paradigm morphology': 'ngram226',\n",
              " 'syntactic island': 'ngram227',\n",
              " 'metrical stress': 'ngram228',\n",
              " 'syntax semantic interface': 'ngram229',\n",
              " 'late merger': 'ngram230',\n",
              " 'wholesale late merger': 'ngram231',\n",
              " 'additive scalar focus particle': 'ngram232',\n",
              " 'lexical meaning change': 'ngram233',\n",
              " 'syntactic position': 'ngram234',\n",
              " 'e type anaphora': 'ngram235',\n",
              " 'internally head relative clause': 'ngram236',\n",
              " 'direct perception report': 'ngram237',\n",
              " 'factive construction': 'ngram238',\n",
              " 'kratzerian situation semantic': 'ngram239',\n",
              " 'modification vs. complementation': 'ngram240',\n",
              " 'theta theory': 'ngram241',\n",
              " 'spanish ditransitive construction': 'ngram242',\n",
              " 'principle and parameter': 'ngram243',\n",
              " 'generative syntax': 'ngram244',\n",
              " 'impersonal pronoun': 'ngram245',\n",
              " 'generic and existential reading': 'ngram246',\n",
              " 'head internal relative clause': 'ngram247',\n",
              " 'doubly headed relative clause': 'ngram248',\n",
              " 'copy theory': 'ngram249',\n",
              " 'chain resolution': 'ngram250',\n",
              " 'maximal informativeness': 'ngram251',\n",
              " 'salient set restriction': 'ngram252',\n",
              " 'cogntitive syntax': 'ngram253',\n",
              " 'the space of possible grammar': 'ngram254',\n",
              " 'bonobo grammar': 'ngram255',\n",
              " 'fundamental grammar': 'ngram256',\n",
              " 'formal language theory': 'ngram257',\n",
              " 'language evolution': 'ngram258',\n",
              " 'free relative': 'ngram259',\n",
              " 'headless relative': 'ngram260',\n",
              " 'cognitive semantic': 'ngram261',\n",
              " 'computational linguistic': 'ngram262',\n",
              " 'philosophy of language': 'ngram263',\n",
              " 'natural language processing': 'ngram264',\n",
              " 'artificial intelligence': 'ngram265',\n",
              " 'tagalog grammar': 'ngram266',\n",
              " 'positive evidence': 'ngram267',\n",
              " 'negative evidence': 'ngram268',\n",
              " 'subset grammar': 'ngram269',\n",
              " 'syllable structure': 'ngram270',\n",
              " 'morphological selection': 'ngram271',\n",
              " 'non finite morphology': 'ngram272',\n",
              " 'ipp effect': 'ngram273',\n",
              " 'ppi effect': 'ngram274',\n",
              " 'swiss german': 'ngram275',\n",
              " 'local dislocation': 'ngram276',\n",
              " 'displace morphology': 'ngram277',\n",
              " 'parasitic morphology': 'ngram278',\n",
              " 'post syntactic morphology': 'ngram279',\n",
              " 'dialect syntax': 'ngram280',\n",
              " 'phrasal affix': 'ngram281',\n",
              " 'syntax phonology interface': 'ngram282',\n",
              " 'verbal stem': 'ngram283',\n",
              " 'prosodic template': 'ngram284',\n",
              " 'vowel length alternation': 'ngram285',\n",
              " 'vowel zero alternation': 'ngram286',\n",
              " 'duality of semantic': 'ngram287',\n",
              " 'case mark': 'ngram288',\n",
              " 'dependent case': 'ngram289',\n",
              " 'accusative case': 'ngram290',\n",
              " 'fate accusative': 'ngram291',\n",
              " 'quirky case': 'ngram292',\n",
              " 'icelandic syntax': 'ngram293',\n",
              " 'weather verb': 'ngram294',\n",
              " 'backward control': 'ngram295',\n",
              " 'error drive learning': 'ngram296',\n",
              " 'argument ellipsis': 'ngram297',\n",
              " 'antecedent contain deletion': 'ngram298',\n",
              " 'uniform atomicity': 'ngram299',\n",
              " 'vp front': 'ngram300',\n",
              " 'freezing effect': 'ngram301',\n",
              " 'successive cyclic movement': 'ngram302',\n",
              " 'verb inflection': 'ngram303',\n",
              " 'descriptive adequacy': 'ngram304',\n",
              " 'type frequency': 'ngram305',\n",
              " 'r epenthesis': 'ngram306',\n",
              " 'faire par': 'ngram307',\n",
              " 'false belief': 'ngram308',\n",
              " 'suspend affixation': 'ngram309',\n",
              " 'postsyntactic reordering': 'ngram310',\n",
              " 'mirror principle': 'ngram311',\n",
              " 'polysemous gender': 'ngram312',\n",
              " 'distribute gender': 'ngram313',\n",
              " 'reduce relative clause': 'ngram314',\n",
              " 'auxiliary verb': 'ngram315',\n",
              " 'tough construction': 'ngram316',\n",
              " 'multi headed constituent': 'ngram317',\n",
              " 'label projection': 'ngram318',\n",
              " 'atb extraction': 'ngram319',\n",
              " 'parasitic gap': 'ngram320',\n",
              " 'binary branching': 'ngram321',\n",
              " 'c command': 'ngram322',\n",
              " 'verb alternation': 'ngram323',\n",
              " 'myer ’s generalization': 'ngram324',\n",
              " 'implicit argument': 'ngram325',\n",
              " 'impersonal se': 'ngram326',\n",
              " 'passive se': 'ngram327',\n",
              " 'inalienable possession': 'ngram328',\n",
              " 'by phrase': 'ngram329',\n",
              " 'person restriction': 'ngram330',\n",
              " 'wh pronoun': 'ngram331',\n",
              " 'subjunctive particle': 'ngram332',\n",
              " 'prepositional complementizer': 'ngram333',\n",
              " 'oblique case': 'ngram334',\n",
              " 'phonological theory': 'ngram335',\n",
              " 'stress vowel': 'ngram336',\n",
              " 'element theory': 'ngram337',\n",
              " 'verb strand verb phrase ellipsis': 'ngram338',\n",
              " 'missing object': 'ngram339',\n",
              " 'proviso problem': 'ngram340',\n",
              " 'pragmatic strengthening': 'ngram341',\n",
              " 'thematic role': 'ngram342',\n",
              " 'proto role': 'ngram343',\n",
              " 'computational model': 'ngram344',\n",
              " 'verbal classifier': 'ngram345',\n",
              " 'the enclitic ta': 'ngram346',\n",
              " 'gestural predicate': 'ngram347',\n",
              " 'identity relation': 'ngram348',\n",
              " 'frege ’s puzzle': 'ngram349',\n",
              " 'neg raising': 'ngram350',\n",
              " 'klima test': 'ngram351',\n",
              " 'sentential negation': 'ngram352',\n",
              " 'strict npis': 'ngram353',\n",
              " 'confirmation tag': 'ngram354',\n",
              " 'negative parenthetical': 'ngram355',\n",
              " 'event semantic': 'ngram356',\n",
              " 'de morgan ’s law': 'ngram357',\n",
              " 'non obligatory control': 'ngram358',\n",
              " 'phi feature': 'ngram359',\n",
              " 'indexical shift': 'ngram360',\n",
              " 'grammatical modularity': 'ngram361',\n",
              " 'pp extraposition': 'ngram362',\n",
              " 'focus particle': 'ngram363',\n",
              " 'arabic dative external possession possessor raising context link grammar': 'ngram364',\n",
              " 'case match': 'ngram365',\n",
              " 'preposition stranding': 'ngram366',\n",
              " 'ellipsis identity': 'ngram367',\n",
              " 'as clause': 'ngram368',\n",
              " 'ellipsis site': 'ngram369',\n",
              " 'variable resolution': 'ngram370',\n",
              " 'strict sloppy identity': 'ngram371',\n",
              " 'pronominal binding': 'ngram372',\n",
              " 'question under discussion': 'ngram373',\n",
              " 'proxy control': 'ngram374',\n",
              " 'deontic modality': 'ngram375',\n",
              " 'obligatory control': 'ngram376',\n",
              " 'proxy anaphora': 'ngram377',\n",
              " 'control shift': 'ngram378',\n",
              " 'phi agreement': 'ngram379',\n",
              " 'brazilian portuguese': 'ngram380',\n",
              " 'primate semantic': 'ngram381',\n",
              " 'primate call evolution': 'ngram382',\n",
              " 'primate implicature': 'ngram383',\n",
              " 'evolution of meaning': 'ngram384',\n",
              " 'evolution of communication': 'ngram385',\n",
              " 'information theory': 'ngram386',\n",
              " 'phonetic implementation': 'ngram387',\n",
              " 'clausal complement': 'ngram388',\n",
              " 'speech act verb': 'ngram389',\n",
              " 'theta system': 'ngram390',\n",
              " 'argument alternation': 'ngram391',\n",
              " 'resumptive pronoun': 'ngram392',\n",
              " 'case attraction': 'ngram393',\n",
              " 'hierarchy effect': 'ngram394',\n",
              " 'matching effect': 'ngram395',\n",
              " 'top down derivation': 'ngram396',\n",
              " 'differential object mark': 'ngram397',\n",
              " 'abruzzese dialect': 'ngram398',\n",
              " 'wh copying': 'ngram399',\n",
              " 'copy theory of movement': 'ngram400',\n",
              " 'syntactic bootstrapping': 'ngram401',\n",
              " 'verb learn': 'ngram402',\n",
              " 'propositional attitude verb': 'ngram403',\n",
              " 'main clause syntax': 'ngram404',\n",
              " 'labeling problem': 'ngram405',\n",
              " 'derivational morphology': 'ngram406',\n",
              " 'particle movement': 'ngram407',\n",
              " 'agent focus': 'ngram408',\n",
              " 'music semantic': 'ngram409',\n",
              " 'music pragmatic': 'ngram410',\n",
              " 'source base semantic': 'ngram411',\n",
              " 'dependent clause': 'ngram412',\n",
              " 'complement pronoun': 'ngram413',\n",
              " 'derive predicate': 'ngram414',\n",
              " 'the generalize control rule': 'ngram415',\n",
              " 'root attachment': 'ngram416',\n",
              " 'historical linguistic': 'ngram417',\n",
              " 'corpus linguistic': 'ngram418',\n",
              " 'language acquisition': 'ngram419',\n",
              " 'dative construction': 'ngram420',\n",
              " 'bayesian inference': 'ngram421',\n",
              " 'maximum entropy': 'ngram422',\n",
              " 'harmonic grammar': 'ngram423',\n",
              " 'index constraint': 'ngram424',\n",
              " 'cophonology theory': 'ngram425',\n",
              " \"lyman 's law\": 'ngram426',\n",
              " 'contextual allomorphy': 'ngram427',\n",
              " 'vocabulary insertion': 'ngram428',\n",
              " 'syntactic category': 'ngram429',\n",
              " 'language change': 'ngram430',\n",
              " \"jespersen 's cycle\": 'ngram431',\n",
              " 'evolutionary game theory': 'ngram432',\n",
              " 'verb projection raising': 'ngram433',\n",
              " '3rd construction': 'ngram434',\n",
              " 'west germanic': 'ngram435',\n",
              " 'displace zu': 'ngram436',\n",
              " 'sluice ellipsis identity copular island': 'ngram437',\n",
              " 'dutch linguistics': 'ngram438',\n",
              " 'collostructional analysis': 'ngram439',\n",
              " 'verb semantic': 'ngram440',\n",
              " 'wh question': 'ngram441',\n",
              " 'partial wh movement': 'ngram442',\n",
              " 'a bar movement': 'ngram443',\n",
              " 'extraction mark': 'ngram444',\n",
              " 'vocal aesthetic': 'ngram445',\n",
              " 'tone manipulation': 'ngram446',\n",
              " 'teach material': 'ngram447',\n",
              " 'syntax morphology interface': 'ngram448',\n",
              " 'realizational morphology': 'ngram449',\n",
              " 'relative tense': 'ngram450',\n",
              " 'dp phase': 'ngram451',\n",
              " 'vp phase': 'ngram452',\n",
              " 'clitic and non clitic pronoun': 'ngram453',\n",
              " 'clitic doubling': 'ngram454',\n",
              " 'syntactic feature': 'ngram455',\n",
              " 'scottish gaelic': 'ngram456',\n",
              " 'evaluative statement': 'ngram457',\n",
              " 'accent identification': 'ngram458',\n",
              " 'speech accent archive': 'ngram459',\n",
              " 'english accent': 'ngram460',\n",
              " 'logical visibility': 'ngram461',\n",
              " 'direct discourse': 'ngram462',\n",
              " 'free indirect discourse': 'ngram463',\n",
              " 'child language': 'ngram464',\n",
              " 'modern greek': 'ngram465',\n",
              " 'lexical case': 'ngram466',\n",
              " 'pronoun copying': 'ngram467',\n",
              " 'automatic annotation': 'ngram468',\n",
              " 'linguistic datum': 'ngram469',\n",
              " 'past participle': 'ngram470',\n",
              " 'information structure': 'ngram471',\n",
              " 'contrastive topicalization': 'ngram472',\n",
              " 'linear correspondance axiom': 'ngram473',\n",
              " 'response particle': 'ngram474',\n",
              " 'syntax of speech act': 'ngram475',\n",
              " 'multi functionality': 'ngram476',\n",
              " 'syntax pragmatic': 'ngram477',\n",
              " 'cumulative reading': 'ngram478',\n",
              " 'pseudo relative': 'ngram479',\n",
              " 'clause level determiner': 'ngram480',\n",
              " 'event kind situation type': 'ngram481',\n",
              " 'derive kind predication': 'ngram482',\n",
              " 'weak definite': 'ngram483',\n",
              " 'fallible agree': 'ngram484',\n",
              " 'fallible control': 'ngram485',\n",
              " 'noun phrase': 'ngram486',\n",
              " 'case stack': 'ngram487',\n",
              " 'case alternation': 'ngram488',\n",
              " 'preposition infinitival construction': 'ngram489',\n",
              " 'numeral semantic': 'ngram490',\n",
              " 'evolutionary biology': 'ngram491',\n",
              " 'theoretical linguistic': 'ngram492',\n",
              " 'comparative animal behavior study': 'ngram493',\n",
              " 'molecular biology': 'ngram494',\n",
              " 'discontinuous past': 'ngram495',\n",
              " 'cessation implicature': 'ngram496',\n",
              " 'trivalent semantic': 'ngram497',\n",
              " 'fake indexical': 'ngram498',\n",
              " 'long distance question formation': 'ngram499',\n",
              " 'relativized probe': 'ngram500',\n",
              " 'reflexive passive': 'ngram501',\n",
              " 'language faculty': 'ngram502',\n",
              " 'specific language impairment': 'ngram503',\n",
              " 'middle english': 'ngram504',\n",
              " 'multivariate modelling': 'ngram505',\n",
              " 'adnominal modifier': 'ngram506',\n",
              " 'defective intervention': 'ngram507',\n",
              " 'indo iranian': 'ngram508',\n",
              " 'language shift': 'ngram509',\n",
              " 'harmonize process': 'ngram510',\n",
              " 'vowel consonant adjacency': 'ngram511',\n",
              " 'epistemic modality': 'ngram512',\n",
              " 'context dependency': 'ngram513',\n",
              " 'inherent case': 'ngram514',\n",
              " 'remnant movement': 'ngram515',\n",
              " 'nez perce': 'ngram516',\n",
              " 'additive particle': 'ngram517',\n",
              " 'discourse particle': 'ngram518',\n",
              " 'presupposition trigger': 'ngram519',\n",
              " 'german noch': 'ngram520',\n",
              " 'chinese hái': 'ngram521',\n",
              " 'hungarian még   gricean maxim': 'ngram522',\n",
              " 'branching time': 'ngram523',\n",
              " 'mixed quotation': 'ngram524',\n",
              " 'ancient greek': 'ngram525',\n",
              " 'root suppletion': 'ngram526',\n",
              " 'formal syntax': 'ngram527',\n",
              " 'double object construction': 'ngram528',\n",
              " 'root meaning': 'ngram529',\n",
              " 'lexical decomposition': 'ngram530',\n",
              " 'change of state verb': 'ngram531',\n",
              " 'deverbal adjective': 'ngram532',\n",
              " 'sublexical modification': 'ngram533',\n",
              " 'focus association': 'ngram534',\n",
              " 'scope reconstruction': 'ngram535',\n",
              " 'syntax of ` only': 'ngram536',\n",
              " 'dative substitution': 'ngram537',\n",
              " 'autonomous morphology': 'ngram538',\n",
              " 'inflectional class': 'ngram539',\n",
              " 'operational definition': 'ngram540',\n",
              " 'natural class': 'ngram541',\n",
              " 'artificial grammar learn': 'ngram542',\n",
              " 'fragment question': 'ngram543',\n",
              " 'contrastive topic': 'ngram544',\n",
              " 'language development': 'ngram545',\n",
              " 'prototype theory': 'ngram546',\n",
              " 'figurative language': 'ngram547',\n",
              " 'formulaic language': 'ngram548',\n",
              " 'idiom comprehension': 'ngram549',\n",
              " 'reaction time': 'ngram550',\n",
              " 'language processing': 'ngram551',\n",
              " 'prototypicality effect': 'ngram552',\n",
              " 'ilgi tümceciği': 'ngram553',\n",
              " 'np ellipsis': 'ngram554',\n",
              " 'strong inflection': 'ngram555',\n",
              " 'adjunction arabic control movement structural theory of predication': 'ngram556',\n",
              " 'special meaning': 'ngram557',\n",
              " 'phase theory': 'ngram558',\n",
              " 'context sensitivity': 'ngram559',\n",
              " 'specificational copular clause': 'ngram560',\n",
              " 'copular clause': 'ngram561',\n",
              " 'polar opposition': 'ngram562',\n",
              " 'scalar adjective': 'ngram563',\n",
              " 'degree semantic': 'ngram564',\n",
              " 'definite article': 'ngram565',\n",
              " 'support morphology': 'ngram566',\n",
              " 'categorial grammar': 'ngram567',\n",
              " 'yes no question': 'ngram568',\n",
              " 'de se': 'ngram569',\n",
              " 'second person': 'ngram570',\n",
              " 'pronoun interpretation': 'ngram571',\n",
              " 'direct indirect speech report': 'ngram572',\n",
              " 'edge requirement': 'ngram573',\n",
              " 'cypriot greek': 'ngram574',\n",
              " 'standard modern greek': 'ngram575',\n",
              " 'verb initial language': 'ngram576',\n",
              " 'head raising': 'ngram577',\n",
              " 'mayan language': 'ngram578',\n",
              " 'association with focus': 'ngram579',\n",
              " 'covert focus movement': 'ngram580',\n",
              " 'covert pie piping': 'ngram581',\n",
              " 'island sensitivity': 'ngram582',\n",
              " 'variable bind': 'ngram583',\n",
              " 'dynamic semantic': 'ngram584',\n",
              " 'language contact': 'ngram585',\n",
              " 'verb third': 'ngram586',\n",
              " 'new germanic variety': 'ngram587',\n",
              " 'sound symbolism': 'ngram588',\n",
              " 'southern min': 'ngram589',\n",
              " 'kind term': 'ngram590',\n",
              " 'keyword passive': 'ngram591',\n",
              " 'multiple agreement': 'ngram592',\n",
              " 'embed imperative': 'ngram593',\n",
              " 'performative modal': 'ngram594',\n",
              " 'speech report': 'ngram595',\n",
              " 'subject obviation': 'ngram596',\n",
              " 'historical syntax': 'ngram597',\n",
              " 'indo european': 'ngram598',\n",
              " 'polar particle': 'ngram599',\n",
              " 'contradiction contour': 'ngram600',\n",
              " 'negative question': 'ngram601',\n",
              " 'inflect infinitive': 'ngram602',\n",
              " 'diachronic change': 'ngram603',\n",
              " 'structure enrichment': 'ngram604',\n",
              " 'dialectal syntactic variation': 'ngram605',\n",
              " 'comparative syntax': 'ngram606',\n",
              " 'romance syntax': 'ngram607',\n",
              " 'disjunctive antecedent': 'ngram608',\n",
              " 'minimal change semantic': 'ngram609',\n",
              " 'inquisitive semantic': 'ngram610',\n",
              " 'web survey': 'ngram611',\n",
              " 'semantic presupposition': 'ngram612',\n",
              " 'two dimensional theory of presupposition': 'ngram613',\n",
              " 'substance free': 'ngram614',\n",
              " 'data structure': 'ngram615',\n",
              " 'set theory': 'ngram616',\n",
              " 'computational phonology': 'ngram617',\n",
              " 'borderline contradiction': 'ngram618',\n",
              " 'scale structure': 'ngram619',\n",
              " 'gradable adjective': 'ngram620',\n",
              " 'semantic selection': 'ngram621',\n",
              " 'computational semantic': 'ngram622',\n",
              " 'quantity expression': 'ngram623',\n",
              " 'linguistic application of measurement theory': 'ngram624',\n",
              " 'compatibility condition': 'ngram625',\n",
              " 'anti honorific': 'ngram626',\n",
              " 'sentential anomaly': 'ngram627',\n",
              " 'presupposition failure': 'ngram628',\n",
              " 'sub- categorization': 'ngram629',\n",
              " 'mass count distinction': 'ngram630',\n",
              " 'quantifier distribution': 'ngram631',\n",
              " 'partial pro drop': 'ngram632',\n",
              " 'null topic': 'ngram633',\n",
              " 'topic prominence': 'ngram634',\n",
              " 'discourse configurationality': 'ngram635',\n",
              " 'double object': 'ngram636',\n",
              " 'west flemish': 'ngram637',\n",
              " 'mass count': 'ngram638',\n",
              " 'plural mass noun': 'ngram639',\n",
              " 'processing complexity': 'ngram640',\n",
              " 'language variation': 'ngram641',\n",
              " 'long distance agreement': 'ngram642',\n",
              " 'predicate inversion': 'ngram643',\n",
              " 'inverse copular': 'ngram644',\n",
              " 'generative grammar': 'ngram645',\n",
              " 'strict negative concord': 'ngram646',\n",
              " 'non strict negative concord': 'ngram647',\n",
              " 'negative polarity': 'ngram648',\n",
              " 'positive polarity': 'ngram649',\n",
              " 'quantifier particle': 'ngram650',\n",
              " 'late adjunct merger': 'ngram651',\n",
              " 'specificational clause': 'ngram652',\n",
              " 'equative clause': 'ngram653',\n",
              " 'affix order': 'ngram654',\n",
              " 'bracketing paradox': 'ngram655',\n",
              " 'dual level affix': 'ngram656',\n",
              " 'interface of phonology': 'ngram657',\n",
              " 'lexical conservatism': 'ngram658',\n",
              " 'lexical phonology and morphology': 'ngram659',\n",
              " 'nonconcatenative exponence': 'ngram660',\n",
              " 'output output correspondence': 'ngram661',\n",
              " 'phonological variability': 'ngram662',\n",
              " 'speech production planning': 'ngram663',\n",
              " 'agreement verb': 'ngram664',\n",
              " 'gestural verb': 'ngram665',\n",
              " 'pro speech gesture': 'ngram666',\n",
              " 'grammaticality judgement': 'ngram667',\n",
              " 'grammaticality intuition': 'ngram668',\n",
              " 'tonal accent': 'ngram669',\n",
              " 'metrical phonology': 'ngram670',\n",
              " 'moraic theory': 'ngram671',\n",
              " 'frame adverbial': 'ngram672',\n",
              " 'temporal adverbial': 'ngram673',\n",
              " 'complex tense': 'ngram674',\n",
              " 'temporal remoteness': 'ngram675',\n",
              " 'contrastive focus': 'ngram676',\n",
              " 'game theory': 'ngram677',\n",
              " 'poverty of the stimulus': 'ngram678',\n",
              " 'p stranding': 'ngram679',\n",
              " 'scope theory of even': 'ngram680',\n",
              " 'backwards association': 'ngram681',\n",
              " 'nominal adjunct': 'ngram682',\n",
              " 'theta role': 'ngram683',\n",
              " 'colour verb': 'ngram684',\n",
              " 'vowel length': 'ngram685',\n",
              " 'consonant length': 'ngram686',\n",
              " 'rule base phonology': 'ngram687',\n",
              " 'substance free phonology': 'ngram688',\n",
              " 'dance cognition': 'ngram689',\n",
              " 'grouping structure': 'ngram690',\n",
              " 'music cognition': 'ngram691',\n",
              " 'functional category': 'ngram692',\n",
              " 'keith tse': 'ngram693',\n",
              " 'three dimensional syntax': 'ngram694',\n",
              " 'verb of say': 'ngram695',\n",
              " 'first language acquisition': 'ngram696',\n",
              " 'rise fall rise': 'ngram697',\n",
              " 'question answer congruence': 'ngram698',\n",
              " 'contextually order alternative': 'ngram699',\n",
              " 'gricean reason- ing': 'ngram700',\n",
              " 'common knowledge': 'ngram701',\n",
              " 'scope freeze': 'ngram702',\n",
              " 'split scope': 'ngram703',\n",
              " 'locality of movement': 'ngram704',\n",
              " 'the phase impenetrability condition': 'ngram705',\n",
              " 'stress assignment': 'ngram706',\n",
              " 'epistemic adverb': 'ngram707',\n",
              " 'modal concord': 'ngram708',\n",
              " 'right node raising': 'ngram709',\n",
              " 'left node raising': 'ngram710',\n",
              " 'functional morpheme': 'ngram711',\n",
              " 'verbal doubling': 'ngram712',\n",
              " 'rioplatense spanish': 'ngram713',\n",
              " 'european portuguese': 'ngram714',\n",
              " 'i assignment': 'ngram715',\n",
              " 'nonfinite complement': 'ngram716',\n",
              " 'focus movement': 'ngram717',\n",
              " 'double negation': 'ngram718',\n",
              " 'contrastive negation': 'ngram719',\n",
              " 'negative affix': 'ngram720',\n",
              " 'reference grammar': 'ngram721',\n",
              " 'introspection research': 'ngram722',\n",
              " 'corpus research': 'ngram723',\n",
              " 'long wh movement': 'ngram724',\n",
              " 'semi passive': 'ngram725',\n",
              " 'tense future': 'ngram726',\n",
              " 'bottleneck effect': 'ngram727',\n",
              " 'feature scatter': 'ngram728',\n",
              " 'clausal leave periphery': 'ngram729',\n",
              " 'child language development': 'ngram730',\n",
              " 'common ground': 'ngram731',\n",
              " 'free choice inference': 'ngram732',\n",
              " 'recursive exhaustification': 'ngram733',\n",
              " 'old italian': 'ngram734',\n",
              " 'jespersen cycle': 'ngram735',\n",
              " 'n word': 'ngram736',\n",
              " 'dialectal variation': 'ngram737',\n",
              " 'alternate verb': 'ngram738',\n",
              " 'aspectual se': 'ngram739',\n",
              " 'alternate motion verb': 'ngram740',\n",
              " 'sentential only': 'ngram741',\n",
              " 'adverb placement': 'ngram742',\n",
              " 'implicative verb': 'ngram743',\n",
              " 'lexical entailment': 'ngram744',\n",
              " 'nominal licensing': 'ngram745',\n",
              " 'abstract case': 'ngram746',\n",
              " 'syntactic diagnostic': 'ngram747',\n",
              " 'case filter': 'ngram748',\n",
              " 'jamaican creole': 'ngram749',\n",
              " 'choice function': 'ngram750',\n",
              " 'reduce relative': 'ngram751',\n",
              " 'infinitival relative': 'ngram752',\n",
              " 'syntactic variation': 'ngram753',\n",
              " 'to construction': 'ngram754',\n",
              " 'event structure': 'ngram755',\n",
              " 'american sign language': 'ngram756',\n",
              " 'weak cross over': 'ngram757',\n",
              " 'non canonical word order': 'ngram758',\n",
              " 'ignorance inference': 'ngram759',\n",
              " 'superlative modifier': 'ngram760',\n",
              " 'semantic information': 'ngram761',\n",
              " 'distributional complexity': 'ngram762',\n",
              " 'lexical bootstrapping': 'ngram763',\n",
              " 'morpho syntax': 'ngram764',\n",
              " 'clausal comparative': 'ngram765',\n",
              " 'phrasal comparative': 'ngram766',\n",
              " 'dutch comparative construction': 'ngram767',\n",
              " 'the agreement hierarchy': 'ngram768',\n",
              " 'austronesian language': 'ngram769',\n",
              " 'subject only restriction': 'ngram770',\n",
              " 'internal reconstruction': 'ngram771',\n",
              " 'voice obstruent': 'ngram772',\n",
              " 'mora count': 'ngram773',\n",
              " 'specificational sentence': 'ngram774',\n",
              " 'copular sentence': 'ngram775',\n",
              " 'quirky subject': 'ngram776',\n",
              " 'grammatical function': 'ngram777',\n",
              " 'crowdsource survey': 'ngram778',\n",
              " 'order semantic': 'ngram779',\n",
              " 'causal reasoning': 'ngram780',\n",
              " 'negative polarity item': 'ngram781',\n",
              " 'weak npis': 'ngram782',\n",
              " 'strong npis': 'ngram783',\n",
              " 'superstrict npis': 'ngram784',\n",
              " 'anti additive': 'ngram785',\n",
              " 'anti morphic': 'ngram786',\n",
              " 'downward entail': 'ngram787',\n",
              " 'liar paradox': 'ngram788',\n",
              " 'tacit knowledge': 'ngram789',\n",
              " 'referential np': 'ngram790',\n",
              " 'ontological commitment': 'ngram791',\n",
              " 'domain specificity': 'ngram792',\n",
              " 'generative function': 'ngram793',\n",
              " 'ture machine': 'ngram794',\n",
              " 'universal generative faculty': 'ngram795',\n",
              " 'experimental design': 'ngram796',\n",
              " 'lexical processing': 'ngram797',\n",
              " 'nonhuman animal': 'ngram798',\n",
              " 'prosodic information': 'ngram799',\n",
              " 'french liaison': 'ngram800',\n",
              " 'word segmentation': 'ngram801',\n",
              " 'distributional cue': 'ngram802',\n",
              " 'abstract knowledge': 'ngram803',\n",
              " 'periphrastic perfect tense': 'ngram804',\n",
              " 'adjectival and verbal participle': 'ngram805',\n",
              " 'copular and semi copular verb': 'ngram806',\n",
              " 'perfect auxiliary': 'ngram807',\n",
              " 'double perfect construction': 'ngram808',\n",
              " 'construction grammar': 'ngram809',\n",
              " 'semantic agreement': 'ngram810',\n",
              " 'language of thought': 'ngram811',\n",
              " 'linguistic competition': 'ngram812',\n",
              " 'donkey sentence': 'ngram813',\n",
              " 'weak strong existential universal ambiguity': 'ngram814',\n",
              " 'extension gap': 'ngram815',\n",
              " 'self talk': 'ngram816',\n",
              " 'secondary selfhood': 'ngram817',\n",
              " 'phase edge': 'ngram818',\n",
              " 'tool grammar': 'ngram819',\n",
              " 'nominal classification': 'ngram820',\n",
              " 'suffix order': 'ngram821',\n",
              " 'degree quantifier': 'ngram822',\n",
              " 'degree variable': 'ngram823',\n",
              " 'element expulsion': 'ngram824',\n",
              " 'vocalic tier': 'ngram825',\n",
              " 'bound lattice': 'ngram826',\n",
              " 'object shift': 'ngram827',\n",
              " 'a scramble': 'ngram828',\n",
              " 'effect on output': 'ngram829',\n",
              " \"holmberg 's generalization\": 'ngram830',\n",
              " 'order preservation': 'ngram831',\n",
              " 'vp topicalization': 'ngram832',\n",
              " 'adjective order': 'ngram833',\n",
              " 'nominal syntax': 'ngram834',\n",
              " 'q adjective': 'ngram835',\n",
              " 'proportional reading': 'ngram836',\n",
              " 'relative reading': 'ngram837',\n",
              " 'abstract agreement': 'ngram838',\n",
              " 'conjunction en': 'ngram839',\n",
              " 'root infinitive': 'ngram840',\n",
              " 'frame setter': 'ngram841',\n",
              " 'main clause external constituent': 'ngram842',\n",
              " 'nominal quantifier': 'ngram843',\n",
              " 'heim kennedy constraint': 'ngram844',\n",
              " 'minority language': 'ngram845',\n",
              " 'phonological typology': 'ngram846',\n",
              " 'probabilistic modeling': 'ngram847',\n",
              " 'sound change': 'ngram848',\n",
              " 'channel bias': 'ngram849',\n",
              " 'post nasal devoicing': 'ngram850',\n",
              " 'formal and semantic agreement': 'ngram851',\n",
              " 'agreement mismatch': 'ngram852',\n",
              " 'agreement hierarchy': 'ngram853',\n",
              " 'clitic second': 'ngram854',\n",
              " 'reflexive adverbial': 'ngram855',\n",
              " 'focus adverb': 'ngram856',\n",
              " 'austronesian syntax': 'ngram857',\n",
              " 'chinese syntax': 'ngram858',\n",
              " 'clause type': 'ngram859',\n",
              " 'split cp': 'ngram860',\n",
              " 'speech act layer': 'ngram861',\n",
              " 'theme vowel': 'ngram862',\n",
              " 'late insertion': 'ngram863',\n",
              " 'suppletive allomorphy': 'ngram864',\n",
              " 'update semantic': 'ngram865',\n",
              " 'dependent indefinite': 'ngram866',\n",
              " 'adjectival argument': 'ngram867',\n",
              " 'left branch extraction': 'ngram868',\n",
              " 'conjunct agreement': 'ngram869',\n",
              " 'linear order': 'ngram870',\n",
              " 'little pro': 'ngram871',\n",
              " 'processing hypothesis': 'ngram872',\n",
              " 'trigram model': 'ngram873',\n",
              " 'information density': 'ngram874',\n",
              " 'uniform information density': 'ngram875',\n",
              " 'russian verbal prefix': 'ngram876',\n",
              " 'syntactic decomposition': 'ngram877',\n",
              " 'functional approach': 'ngram878',\n",
              " 'form mean relationship': 'ngram879',\n",
              " 'derivational affix': 'ngram880',\n",
              " 'stress behaviour': 'ngram881',\n",
              " 'categorial flexibility': 'ngram882',\n",
              " 'phasal spell out': 'ngram883',\n",
              " 'fseq zone': 'ngram884',\n",
              " 'lepore and stone': 'ngram885',\n",
              " 'david lewis': 'ngram886',\n",
              " 'toba batak': 'ngram887',\n",
              " 'austronesian voice': 'ngram888',\n",
              " 'extraction asymmetry': 'ngram889',\n",
              " 'licensing by adjacency': 'ngram890',\n",
              " 'c and t': 'ngram891',\n",
              " 'head bundle': 'ngram892',\n",
              " 'composite probe': 'ngram893',\n",
              " 'multiple spell out': 'ngram894',\n",
              " 'tone sandhi': 'ngram895',\n",
              " 'the csj': 'ngram896',\n",
              " 'null operator construction': 'ngram897',\n",
              " 'gap degree phrase': 'ngram898',\n",
              " 'pretty predicate': 'ngram899',\n",
              " 'gorgia toscana': 'ngram900',\n",
              " 'strict cv': 'ngram901',\n",
              " 'interlude theory': 'ngram902',\n",
              " 'multiple exponence': 'ngram903',\n",
              " 'mora timing': 'ngram904',\n",
              " 'primate pragmatic': 'ngram905',\n",
              " 'monkey call': 'ngram906',\n",
              " 'clause nominalization': 'ngram907',\n",
              " 'anti agreement': 'ngram908',\n",
              " 'wh agreement': 'ngram909',\n",
              " 'null clitic': 'ngram910',\n",
              " 'clitic dependency': 'ngram911',\n",
              " 'yoruba npis': 'ngram912',\n",
              " 'morphologically condition phonology': 'ngram913',\n",
              " 'stress window': 'ngram914',\n",
              " 'co phonology': 'ngram915',\n",
              " 'frequency code hypothesis': 'ngram916',\n",
              " 'formal analysis': 'ngram917',\n",
              " 'chain shift': 'ngram918',\n",
              " 'output drivenness': 'ngram919',\n",
              " 'feature identity': 'ngram920',\n",
              " 'constraint base phonology': 'ngram921',\n",
              " 'theory of faithfulness': 'ngram922',\n",
              " 'local accommodation': 'ngram923',\n",
              " 'nuclear stress': 'ngram924',\n",
              " 'antipronominal context': 'ngram925',\n",
              " 'trace conversion': 'ngram926',\n",
              " 'late merge': 'ngram927',\n",
              " 'contiguity theory': 'ngram928',\n",
              " 'pie piping': 'ngram929',\n",
              " 'match theory': 'ngram930',\n",
              " 'the ocp labial effect': 'ngram931',\n",
              " 'grassfield bantu': 'ngram932',\n",
              " 'exhaustive focus': 'ngram933',\n",
              " 'focus encoding': 'ngram934',\n",
              " 'verbal morphosyntax': 'ngram935',\n",
              " 'interface of syntax and information structure': 'ngram936',\n",
              " 'discourse marker': 'ngram937',\n",
              " 'discourse corpus': 'ngram938',\n",
              " 'statistical association': 'ngram939',\n",
              " 'lexical cue': 'ngram940',\n",
              " 'discourse relation': 'ngram941',\n",
              " 'spurious se': 'ngram942',\n",
              " 'compound tense': 'ngram943',\n",
              " 'main clause': 'ngram944',\n",
              " 'strong uniformity': 'ngram945',\n",
              " 'quantity sensitivity': 'ngram946',\n",
              " 'language universal': 'ngram947',\n",
              " 'phonology phonetic interface': 'ngram948',\n",
              " 'phonetic interpretation': 'ngram949',\n",
              " 'empty nucleus': 'ngram950',\n",
              " 'diachronic phonology': 'ngram951',\n",
              " 'case assignment': 'ngram952',\n",
              " 'give before new': 'ngram953',\n",
              " 'stress give': 'ngram954',\n",
              " 'acceptability rating experiment': 'ngram955',\n",
              " 'multiple regression': 'ngram956',\n",
              " 'unpunctuated repetition': 'ngram957',\n",
              " 'punctuate repetition': 'ngram958',\n",
              " 'continuous repetition': 'ngram959',\n",
              " 'uto aztecan': 'ngram960',\n",
              " 'stress typology': 'ngram961',\n",
              " 'corpus phonology': 'ngram962',\n",
              " 'lexical frequency': 'ngram963',\n",
              " 'external sandhi': 'ngram964',\n",
              " 'russian formalism': 'ngram965',\n",
              " 'socialist realism': 'ngram966',\n",
              " 'final over final condition': 'ngram967',\n",
              " 'word order universal': 'ngram968',\n",
              " 'articulated pp structure': 'ngram969',\n",
              " 'vowel harmony': 'ngram970',\n",
              " 'theory of grammaticalization': 'ngram971',\n",
              " 'cartographic approach': 'ngram972',\n",
              " 'affective construction': 'ngram973',\n",
              " 'dialect grammar': 'ngram974',\n",
              " 'modifier scope adverb': 'ngram975',\n",
              " 'negative event': 'ngram976',\n",
              " 'adjunct clause': 'ngram977',\n",
              " 'fragment answer': 'ngram978',\n",
              " 'criterial position': 'ngram979',\n",
              " 'label algorithm': 'ngram980',\n",
              " 'scandinavian object shift': 'ngram981',\n",
              " 'icelandic stylistic fronting': 'ngram982',\n",
              " 'post supposition': 'ngram983',\n",
              " 'lexical aspect': 'ngram984',\n",
              " 'clause embed': 'ngram985',\n",
              " 'change of state': 'ngram986',\n",
              " 'link theory': 'ngram987',\n",
              " 'generative model': 'ngram988',\n",
              " 'apparent time': 'ngram989',\n",
              " 'corpus gesproken nederlands': 'ngram990',\n",
              " 'e type pronoun': 'ngram991',\n",
              " 'subject specificity': 'ngram992',\n",
              " 'rule h': 'ngram993',\n",
              " 'semantic pragmatic interface': 'ngram994',\n",
              " 'truth value gap': 'ngram995',\n",
              " 'verb class': 'ngram996',\n",
              " 'motion typology': 'ngram997',\n",
              " 'empty position': 'ngram998',\n",
              " 'l1 attrition': 'ngram999',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente es una función que reemplaza los n-grams en un texto por su correspondiente placeholder. No la vamos a correr. La pongo para que vean cómo funciona."
      ],
      "metadata": {
        "id": "iAGATIodvyAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_ngrams(cell):\n",
        "\n",
        "    '''\n",
        "    This replaces the n-gram keywords in the abstract.\n",
        "    '''\n",
        "\n",
        "    for ngram, dummy_token in n_gram_dict.items():\n",
        "\n",
        "        # This finds the ngrams in the text\n",
        "        pattern = r'\\b' + re.escape(ngram) + r'\\b'\n",
        "\n",
        "        # And this replaces the ngrams with a token\n",
        "        cell = re.sub(pattern, dummy_token, cell, flags=re.IGNORECASE)\n",
        "\n",
        "    return cell"
      ],
      "metadata": {
        "id": "63d-6kpvunrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a importar uno de los modelos con los que funciona *LingPeer* para probarlo, junto con su correspondiente vectorización."
      ],
      "metadata": {
        "id": "zsM4FnYy2RqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O classifier1.pkl https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/classifier1.pkl\n",
        "classifier1 = joblib.load(\"classifier1.pkl\")\n",
        "\n",
        "!wget -O c_vect1.pkl https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/c_vect1.pkl\n",
        "c_vect1 = joblib.load(\"c_vect1.pkl\")"
      ],
      "metadata": {
        "id": "uxUg7nEVv8kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7610e35-67e4-4326-fa57-c754ecb620f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 22:49:51--  https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/classifier1.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/classifier1.pkl [following]\n",
            "--2025-07-30 22:49:51--  https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/classifier1.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43164143 (41M) [application/octet-stream]\n",
            "Saving to: ‘classifier1.pkl’\n",
            "\n",
            "classifier1.pkl     100%[===================>]  41.16M   159MB/s    in 0.3s    \n",
            "\n",
            "2025-07-30 22:49:51 (159 MB/s) - ‘classifier1.pkl’ saved [43164143/43164143]\n",
            "\n",
            "--2025-07-30 22:49:51--  https://github.com/cmunozperez/LingPeer/raw/refs/heads/master/LingPeer/c_vect1.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.2.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302 Found\n",
            "Location: https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/c_vect1.pkl [following]\n",
            "--2025-07-30 22:49:52--  https://raw.githubusercontent.com/cmunozperez/LingPeer/refs/heads/master/LingPeer/c_vect1.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334807 (327K) [application/octet-stream]\n",
            "Saving to: ‘c_vect1.pkl’\n",
            "\n",
            "c_vect1.pkl         100%[===================>] 326.96K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-30 22:49:52 (7.15 MB/s) - ‘c_vect1.pkl’ saved [334807/334807]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.2.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente es la función que pone en funcionamiento el modelo. Básicamente, toma un abstract y devuelve una lista ordenada de autores de acuerdo al \"puntaje\" que les asigna el clasificador naive Bayes."
      ],
      "metadata": {
        "id": "e4Ursx0N25WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model1(abstract):\n",
        "    # This vectorizes the provided abstract\n",
        "    abstract_vect = c_vect1.transform([abstract])\n",
        "\n",
        "    # This gets the probabilities for each of the authors in the database\n",
        "    pred_proba = classifier1.predict_proba(abstract_vect.reshape(1, -1))\n",
        "\n",
        "    class_labels = classifier1.classes_\n",
        "\n",
        "    class_labels = [str(i) for i in class_labels]\n",
        "\n",
        "    # This combines the probabilities with each of the authors\n",
        "    class_probabilities = [(label, prob) for label, prob in zip(class_labels, pred_proba[0])]\n",
        "\n",
        "    # Sort class probabilities in descending order\n",
        "    class_probabilities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return class_probabilities"
      ],
      "metadata": {
        "id": "M9T9AFR725hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos una función para probar este modelo de *LingPeer*. La idea es obtener los diez mejores revisores en el repositorio para un cierto abstract."
      ],
      "metadata": {
        "id": "0GQfD_Kw3eDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probar_lingpeer():\n",
        "    abstract = input(\"Dame un abstract y te tiro diez nombres de revisores: \")\n",
        "    predict = model1(abstract)\n",
        "    return predict[:10]"
      ],
      "metadata": {
        "id": "NM0HADR6yVQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probar_lingpeer()"
      ],
      "metadata": {
        "id": "Rl1jPM3Yyhno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8dbf54-ae32-4579-c2e9-36a108793440"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dame un abstract y te tiro diez nombres de revisores: This paper examines metaphor through the lens of Conceptual Blending Theory, as developed by Fauconnier and Turner. Unlike more traditional approaches such as Conceptual Metaphor Theory (Lakoff & Johnson), which map elements between source and target domains, Conceptual Blending emphasizes the dynamic integration of multiple mental spaces to create novel meaning. In the case of metaphor, this theory explains how elements from different domains combine within an emergent blended space, producing interpretations that are creative and context-sensitive. Drawing on examples from contemporary Spanish, the study demonstrates how conceptual blending operates not only in conventional metaphors (time is money), but also in novel and humorous expressions, revealing the cognitive flexibility underlying metaphorical language. This approach offers a more nuanced account of the mental processes involved in metaphor construction and interpretation, highlighting the central role of conceptual imagination in everyday discourse.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Prakash Mondal', np.float64(0.5314076273744693)),\n",
              " ('Ailís Cournane', np.float64(0.08241300247311187)),\n",
              " ('Canaan Breiss', np.float64(0.07574595057197107)),\n",
              " ('Roni Katzir', np.float64(0.06720091476867822)),\n",
              " ('Itamar Kastner', np.float64(0.04954090363291377)),\n",
              " ('Deniz Satik', np.float64(0.044046661283897615)),\n",
              " ('Friederike Moltmann', np.float64(0.04179008641720001)),\n",
              " ('Jianrong Yu', np.float64(0.01246300240903974)),\n",
              " ('Linmin Zhang', np.float64(0.01051706879394939)),\n",
              " ('Martin Haspelmath', np.float64(0.010007492090832102))]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4whwkfXwzt0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}